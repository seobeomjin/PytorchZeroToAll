{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1 : 0.3567\n",
      "Loss2 : 2.3026\n",
      "PyTorch Loss1 : 0.4170 \n",
      "PyTorch Loss2 : 1.8406\n",
      "Y_pred1 : 0\n",
      "Y_pred2 : 1\n",
      "Batch Loss1 : 0.4966 \n",
      "Batch Loss2 : 1.2389\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, tensor, max \n",
    "import numpy as np \n",
    "\n",
    "# Cross entropy example \n",
    "# One hot \n",
    "# 0 : 1 0 0 \n",
    "# 1 : 0 1 0 \n",
    "# 2 : 0 0 1 \n",
    "\n",
    "Y = np.array([1,0,0])\n",
    "Y_pred1 = np.array([0.7,0.2,0.1])\n",
    "Y_pred2 = np.array([0.1,0.3,0.6])\n",
    "print(f'Loss1 : {np.sum(-Y*np.log(Y_pred1)):.4f}')\n",
    "print(f'Loss2 : {np.sum(-Y*np.log(Y_pred2)):.4f}')\n",
    "\n",
    "#### -- (1) single label -- ##### \n",
    "\n",
    "###  criterion instantiate\n",
    "# Softmax + CrossEntropy (logSoftmax + NLLLoss)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "###  Y,Y_pred1,Y_pred2 instantiate  \n",
    "# target is of size nBatch              \n",
    "# each element in target has to gave 0 <= value < nClasses (0-2)\n",
    "# Input is class, not one-hot               \n",
    "Y = tensor([0],requires_grad = False)\n",
    "\n",
    "# input is of size nBatch x nClasses = 1 x 4 \n",
    "# Y_pred are logits (not passed softmax)\n",
    "Y_pred1 = tensor([[2.0,1.0,0.1]])          \n",
    "Y_pred2 = tensor([[0.5,2.0,0.3]])\n",
    "\n",
    "###  get loss\n",
    "l1 = loss(Y_pred1,Y)\n",
    "l2 = loss(Y_pred2,Y)\n",
    "\n",
    "### get result \n",
    "print(f'PyTorch Loss1 : {l1.item():.4f} \\nPyTorch Loss2 : {l2.item():.4f}')\n",
    "print(f'Y_pred1 : {max(Y_pred1.data, 1)[1].item()}') ###### Y_pred1의 data tesnor의[1]요소 >>> tensor([0]) 반환, pred 값\n",
    "print(f'Y_pred2 : {max(Y_pred2.data, 1)[1].item()}')\n",
    "\n",
    "\n",
    "#### -- (2) multiple labels with batch mode -- #####\n",
    "\n",
    "###  Y, Y_pred1, Y_pred2 instantiate\n",
    "# target is of size nBatch \n",
    "# each element in target has to have 0 <= value < nClasses (0-2)\n",
    "# Input is class, not one-hot \n",
    "Y = tensor([2,0,1], requires_grad = False)\n",
    "\n",
    "# input is of size nBatch x nClasses = 2 x 4 \n",
    "# Y_pred are logits (not softmax)\n",
    "Y_pred1 = tensor([[0.1,0.2,0.9],\n",
    "                [1.1, 0.1,0.2],\n",
    "                [0.2,2.1,0.1]])\n",
    "\n",
    "Y_pred2 = tensor([[0.8,0.2,0.3],\n",
    "                 [0.2,0.3,0.5],\n",
    "                 [0.2,0.2,0.5]])\n",
    "### getting loss \n",
    "l1 = loss(Y_pred1, Y)\n",
    "l2 = loss(Y_pred2, Y)\n",
    "\n",
    "### gettinh result \n",
    "print(f'Batch Loss1 : {l1.item():.4f} \\nBatch Loss2 : {l2.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISSUE \n",
    "\n",
    "1) target is of size nBatch (line 23) << think) it means Y's size is same of nBatch ? Y_pred1 and 2 ?  <br>\n",
    "2) Input is class, not one-hot (line 26, 49) << how is it possible as a tensor functionaly? <br>\n",
    "3) each element in target has to have 0 <= value < nClasses (0-2) << what's mean <br>\n",
    "\n",
    "- This criterion expects a a class index in the range [0,C-1] as the target for each value of a 1D tensor of \n",
    "size minibatch <br>\n",
    "- target(N) where each value is 0 <= targets[i] <= C-1 <br>\n",
    "\n",
    "4) Y_pred1 = tensor([[blah blah]]) (line 53) << Y_pred is wrapping twice ,, so that Y can operate as classes ??  <br><br> \n",
    "Inupt (Y_pred)\n",
    "- is expected to contain raw, uncormalized scores for each class.<br>\n",
    "- a tensor of size either (minibatch, C) <br> \n",
    "- input(N,C) where C = number of classes , or (N,C,d1,d2,...,dk) with k>=1. N = minibatch <br>\n",
    "\n",
    "5) torch.max(Y_pred1.data, 1)[1].item() (lien 39) << what's mean <br>\n",
    "- torch.max 함수는 주어진 텐서 배열의 최대 값이 들어있는 index를 리턴하는 함수 \n",
    "- Y_pred = [ [0.3,0.2,0.9,0.1] ] 의 경우 torch.max(Y_pred.data , 1 ) 의 결과는 0.9의 인덱스인 2가 된다. \n",
    "-  뒤의 1 은 dimension에 대한 것이다. e,g) 64 * 10개의 Y_pred 값을 한번에 넣어주고 64개의 예측값을 받아야 하는 경우\n",
    "- ▲ still issue ) 헌데 아직, torch.max(output.data,1) 뒤의 [1].item() 는 완벽히 이해하지 못함\n",
    "```python\n",
    "\n",
    "    print(\"{} : \".format('max(Y_pred1.data,1)'), max(Y_pred1.data,1)) \n",
    "    # >>> torch.return_types.max(values=tensor([2.]),indices=tensor([0]))\n",
    "    print(\"{} : \".format('max(Y_pred1.data,1)[1]'), max(Y_pred1.data,1)[1]) \n",
    "    # >>>  tensor([0])  #[1] idx가 y_pred의 예측 레이블 텐서인 것으로 추정된다. \n",
    "    print(\"{} : \".format('max(Y_pred1.data,1)[1].item()'), max(Y_pred1.data,1)[1].item()) \n",
    "    # >>>  0  #[1].item() 이므로 예측 레이블 텐서의 스칼라 값을 반환한다. 즉, 예측 레이블을 반환한다. \n",
    "```\n",
    "\n",
    "6) Input is of size nBatch x nClasses = 2 x 4 << what's mean <br>\n",
    "- ▲ still issue ) 왜 사이즈가 2 x 4 이지"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "develroom-pytorch",
   "language": "python",
   "name": "develroom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
