{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "from __future__ import print_function \n",
    "## using for python 3.x keywords and features in python 2. > for compatibility \n",
    "\n",
    "from torch import nn, optim, cuda \n",
    "from torch.utils import data \n",
    "## in this module, there are Dataset and DataLoader ,, etc.\n",
    "## data.Dataset >> is using for virtual class for custom data\n",
    "## data.DataLoader >> is using for input Pipeline\n",
    "\n",
    "from torchvision import datasets, transforms \n",
    "## The torchvision package consists of popular datasets, model architectures, \n",
    "## and common image transformations for computer vision.\n",
    "\n",
    "import torch.nn.functional as F \n",
    "import time\n",
    "\n",
    "#Training settings \n",
    "batch_size = 64 \n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f'Training MNIST on {device}\\n {\"=\"*40}')\n",
    "\n",
    "#MNIST Dataset \n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=True,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                             train=False,\n",
    "                             transform=transforms.ToTensor())\n",
    "\n",
    "#Data Loader (Input Pipeline)\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                            batch_size = batch_size,\n",
    "                            shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.l1 = nn.Linear(784,520)\n",
    "        self.l2 = nn.Linear(520,320)\n",
    "        self.l3 = nn.Linear(320,240)\n",
    "        self.l4 = nn.Linear(240,120)\n",
    "        self.l5 = nn.Linear(120,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,784) # Flatten the data (n,1,28,28) -> (n,784) \n",
    "        ## i think > n is batch_size,, (?)\n",
    "        ## such as view of DataBase (?) \n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)\n",
    "    \n",
    "model = Net()\n",
    "model.to(device)  \n",
    "## i think > it send model to device\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01,momentum=0.5)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()  # >> i think ,, overriding\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #sending data and target to device\n",
    "        \n",
    "        '''\n",
    "        Reference) \n",
    "        \n",
    "        for i,data in enumerate(train_loader,0):\n",
    "            #get the inputs \n",
    "            inputs, labels = data\n",
    "        \n",
    "        the data shape looks like,, \n",
    "        [tensor([[],[],...,[]]),tensor([[],[],[],...,[]])]\n",
    "        for inputs and then for labels \n",
    "        \n",
    "        >>>  list(tensor(inputs), tensor(data)) <<< \n",
    "        type(data) >> class 'list'\n",
    "        type(data[0]) >> Torch.Tensor\n",
    "        '''\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0: \n",
    "            print('Train Epoch : {} | Batch Status : {}/{} ({:.0f}%) | Loss : {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item())) \n",
    "            \n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader : \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        #sum up batch loss \n",
    "        tset_loss += criterion(output,target).item()\n",
    "        #get the index of the max\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'======================\\nTest set: Average loss : {test_loss:.4f},Accuracy:{correct}/{len(test_loader.dataset)}'\n",
    "         f'({100.*correct / len(test_loader.dataset):.0f}%)')\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    since = time.time()\n",
    "    for epoch in range(1,10):\n",
    "        epoch_start = time.time()\n",
    "        train(epoch)\n",
    "        m,s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Training time : {m:.0f}m {s:.0f}s')\n",
    "        \n",
    "    m,s = divmod(time.time() - since, 60)\n",
    "    print(f'Total Time: {m:.0f}m {s:.0f}s \\n Model was trained on {device}!')\n",
    "        \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1663,  1.1857,  1.0400,  0.5672],\n",
      "        [-1.5602, -0.8451,  0.3930, -0.1837],\n",
      "        [ 0.2274, -0.4366, -1.2270, -0.2365],\n",
      "        [-0.1978,  0.4887,  1.2223,  0.7826]]) \n",
      " tensor([ 0.1663,  1.1857,  1.0400,  0.5672, -1.5602, -0.8451,  0.3930, -0.1837,\n",
      "         0.2274, -0.4366, -1.2270, -0.2365, -0.1978,  0.4887,  1.2223,  0.7826]) \n",
      " tensor([[ 0.1663,  1.1857,  1.0400,  0.5672, -1.5602, -0.8451,  0.3930, -0.1837],\n",
      "        [ 0.2274, -0.4366, -1.2270, -0.2365, -0.1978,  0.4887,  1.2223,  0.7826]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8)\n",
    "\n",
    "print(x,'\\n',y,'\\n',z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "develroom-pytorch",
   "language": "python",
   "name": "develroom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
